{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create a pipeline using components with Python SDKv2\n",
    "\n",
    "To create a pipeline you can load registered components or components from a yaml file. Here I do both to create my pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the registered data prep component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "ml_client = MLClient.from_config(credential=DefaultAzureCredential(), path=\"./\")\n",
    "\n",
    "data_prep = ml_client.components.get(\n",
    "    name = \"data_prep_diabetes\",\n",
    "    version = <>\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the training component from a yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the component package\n",
    "\n",
    "from azure.ai.ml import load_component\n",
    "\n",
    "# loading the component from the yml file (not registered one)\n",
    "\n",
    "train_component = load_component(source=\"p04_training.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import dsl, Input, Output\n",
    "\n",
    "@dsl.pipeline(\n",
    "    compute=<>,\n",
    "    description= \"diabetes pipeline\",\n",
    ")\n",
    "def diabetes_pipeline(\n",
    "    pipeline_job_input_data,\n",
    "):\n",
    "    #using the data_prep function like a python call with its own inputs\n",
    "    data_prep_job = data_prep(\n",
    "        input_data = pipeline_job_input_data\n",
    "    )\n",
    "\n",
    "    # using the train_func like a python call with its own inputs\n",
    "    train_job = train_component(\n",
    "        prepped_data = data_prep_job.outputs.prepped_data, # using outputs from previous step\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"pipeline_job_prepped_data\": data_prep_job.outputs.prepped_data,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now use your pipeline definition to instantiate a pipeline with your dataset, this example loads my filepath from my data asset (uri file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_data = ml_client.data.get(name=\"diabetes\", version=\"1\")\n",
    "print(f\"data asset uri: {diabetes_data.path}\")\n",
    "\n",
    "pipeline = diabetes_pipeline(\n",
    "    pipeline_job_input_data = Input(type=\"uri_file\", path=diabetes.path),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "submit the job to our workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline,\n",
    "    #projects name\n",
    "    experiment_name = \"diabetes_classification\",\n",
    "    description = \"my description\"\n",
    ")\n",
    "\n",
    "ml_client.jobs.stream(pipeline_job.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
